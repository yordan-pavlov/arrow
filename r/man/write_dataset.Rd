% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dataset-write.R
\name{write_dataset}
\alias{write_dataset}
\title{Write a dataset}
\usage{
write_dataset(
  dataset,
  path,
  format = dataset$format$type,
  schema = dataset$schema,
  partitioning = dplyr::group_vars(dataset),
  hive_style = TRUE,
  ...
)
}
\arguments{
\item{dataset}{\link{Dataset}, \link{RecordBatch}, \link{Table}, \code{arrow_dplyr_query}, or
\code{data.frame}. If an \code{arrow_dplyr_query} or \code{grouped_df},
\code{schema} and \code{partitioning} will be taken from the result of any \code{select()}
and \code{group_by()} operations done on the dataset. Note that \code{filter()} queries
are not currently supported, and \code{select}-ed columns may not be renamed.}

\item{path}{string path to a directory to write to (directory will be
created if it does not exist)}

\item{format}{file format to write the dataset to. Currently supported
formats are "feather" (aka "ipc") and "parquet". Default is to write to the
same format as \code{dataset}.}

\item{schema}{\link{Schema} containing a subset of columns, possibly reordered,
in \code{dataset}. Default is \code{dataset$schema}, i.e. all columns.}

\item{partitioning}{\code{Partitioning} or a character vector of columns to
use as partition keys (to be written as path segments). Default is to
use the current \code{group_by()} columns.}

\item{hive_style}{logical: write partition segments as Hive-style
(\code{key1=value1/key2=value2/file.ext}) or as just bare values. Default is \code{TRUE}.}

\item{...}{additional format-specific arguments. For available Parquet
options, see \code{\link[=write_parquet]{write_parquet()}}.}
}
\value{
The input \code{dataset}, invisibly
}
\description{
This function allows you to write a dataset. By writing to more efficient
binary storage formats, and by specifying relevant partitioning, you can
make it much faster to read and query.
}
